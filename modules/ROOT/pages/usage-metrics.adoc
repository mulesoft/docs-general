= Usage and Pricing Metrics Reference
:page-aliases: pricing-metrics.adoc

Anypoint Platform captures usage metrics across products, but not all metrics are billable or reflected in usage reports.

[cols=3*]
|===
|Product |Metric Description |Usage Details

.6+|Mule Runtime	
|Mule flow: A flow within a deployed and running Mule app that contains a Mule event source or route APIKit request. 
|Flows are aggregated using a Max Concurrent model. The usage for a month is the highest number of flows that exist in a single given hour during a month.

|Mule message: The container of the core information processed by the runtime. 
|A Mule message counts as a single unit when an event source triggers it. Messages are aggregated using a sum of all messages sent during a month.
|Data throughput: The total amount of data transferred in and out of the infrastructure that runs Mule where the Mule app is deployed. 
|Data throughput counts when the deployed application transfers data to execute its business logic, including but not limited to internal operational network traffic for monitoring, logs, and health checks. Data throughput is aggregated as a sum of all bytes during a month. 
| Cluster: A set of servers that act as a single deployment target.
| Cluster capacity is determined by your cluster configuration. 
| CPU Limit: The maximum amount of CPU resources that a worker node can use.
| The CPU limit is aggregated by measuring the amount of CPU usage over a specific period of time, such as an hour or a day. This data is collected and aggregated to calculate the total CPU usage for a particular application. 
| CPU Reserve (Millicores): A guaranteed minimum amount of CPU resources allocated to a worker node. 
| CPU reserve is aggregated by calculating the total amount of CPU resources reserved across all applications in the worker nodes. The aggregated CPU reserve is then used to determine the total amount of CPU usage. 

|API Manager	
|API instance under management: API instances that are managed by API Manager after they are created using add, promote, or import options. 
|API instances remain under management until they are deleted. Instances of API Manager are aggregated using a Max Concurrent model. 

|API Governance	
|API under Governance: APIs identified by the selection criteria of at least one of the governance profiles. 
a|If an API is governed, all versions of that API are considered one governed API. Instances of API Governance are aggregated using a Max Concurrent model. The usage for a month is the highest number of APIs governed in a single given hour during a month.

|Flex Gateway	
|Flex Gateway API call: Any access request received by Anypoint Flex Gateway regardless of whether the response to the request is successful or not. 
|Flex Gateway requests are aggregated as a sum of all requests during a month.

|Composer	
|Composer task: Any action executed on a Composer connector, including but not limited to read, create, update, and delete. 
|Composer tasks are aggregated as a sum of all actions during a month.

|RPA	
|Robotic Process Automation (“RPA”) bot minutes: The number of minutes running process automations across all bot sessions. 
|A single bot can run multiple parallel sessions, with RPA bot minutes counting for each parallel session. You can configure multiple bots to run the same process, with RPA bot minutes counting for each of these separate bot sessions. Test runs or process runs in the test phase are also counted towards RPA bot minutes.

|Message Queue	
|Anypoint MQ API request: A request made to retrieve one or more messages from the Anypoint MQ APIs. 
|Each Anypoint MQ API request includes up to 100 KB of data. An Anypoint MQ API request over 100 KB counts as multiple requests with no fractional units. Anypoint MQ API requests are calculated in the aggregate across all environments (including production, pre-production, sandbox, and design). Anypoint MQ API requests are currently available only via API and aren’t aggregated on usage reports.

|Object Store	
|Object Store API request: A request made to retrieve one or more messages from the Object Store APIs as further defined in the Object Store documentation. 
|Each Object Store API request includes up to 100 KB of data. Object Store API requests over 100 KB count as multiple requests with no fractional units. Object Store API requests are currently available only via API and aren’t aggregated on usage reports.

|DataGraph	
|DataGraph orchestration: An API request made by Anypoint DataGraph to the source APIs to get data for the GraphQL API request made to Anypoint DataGraph. 
|Orchestrations are not currently aggregated on usage reports.

| Intelligent Document Processing (IDP)
| Intelligent Document Processing (IDP) Document Pages: A single page processed by IDP.
| IDP document actions might process documents that have more than one page, with each page counting separately. When RPA executes document actions, it also counts towards document pages and additionally consumes the corresponding RPA Bot Minutes, accounting for the time the RPA process runs.
|===

== API Experience Hub Usage

API Experience Hub usage reports show this information in tables and cards:

include::partial$api-eh-metrics.adoc[tag=table]

include::partial$api-eh-metrics.adoc[tag=card]

== API Governance Usage

API Governance usage reports show this information in tables and cards:

include::partial$api-governance-metrics.adoc[tag=table]

Maximum Number of Governed APIs::
Highest number of APIs governed in a single given hour during a month

== API Manager Usage

API Manager usage reports show this information in tables and cards:

include::partial$apim-metrics.adoc[tag=table]

Maximum Number of Managed APIs::
API instances managed by API Manager

== Flex Gateway Usage

Flex Gateway usage reports show this information in tables and cards:

include::partial$flex-gateway-metrics.adoc[tag=table]

include::partial$flex-gateway-metrics.adoc[tag=card]

== Intelligent Document Processing (IDP)

IDP usage reports show this information in tables and cards:

Business Group::
Business group in which the document is processed

Action ID::
ID associated with the processed action

Action Version::
Version associated with the processed action

Execution Type::
Execution types associated with the processed action

Processed Pages::
Sum of pages processed


== Mule Runtime Usage

MuleSoft captures usage data for Mule flows, Mule messages, and data throughput, but not all of this data is aggregated in usage reports.  

To track Mule message usage, the runtime report counts the number of times a Mule event source triggers a Mule message. You can view the number of these messages in a given day or month by business group, environment, and application. 

To calculate usage, MuleSoft meters and aggregates the number of messages daily and monthly. After a message is triggered, the report doesn't track changes to the message because the message is processed within the application’s flows.

Data throughput is the network I/O bytes produced by the infrastructure that runs the Mule runtime engine running the Mule application. 

To calculate usage, MuleSoft tracks GB usage and aggregates the total daily and monthly GBs.

For select customers in the US control plane, MuleSoft offers a pricing and packaging model for Anypoint Platform that allots a number of Mule flows, Mule messages, and data throughput (measured as network I/O bytes). Not all types of Mule flows and messages count toward the allotments in a package.

=== Mule Runtime Usage Tables

The usage information shown in the usage report tables changes depending on the view you are in.

==== Business Group Details

Select the *Business Group Details* tab to view:

[%header%autowidth.spread]
|===
|Field | Description

|Business Group |The business group a Mule app is deployed to

|Environment Type |The environment in which a Mule app is deployed.

| Cluster |The name of the cluster containing the replicas and worker nodes.

|Cluster Capacity (Millicores) | The worker node capacity.
|===

==== Application Details

Select the *Application Details* tab to view:

[%header%autowidth.spread]
|===
|Field |Description
|Application |The name of the Mule application.

| Business Group | The business group a Mule app is deployed to.

| Deployment Type | The runtime plane to which the Mule app is deployed. CloudHub (abbreviated as CH), CloudHub 2.0 (abbreviated as CH2), and Runtime Fabric (abbreviated as RTF) are supported. 

|Environment Type |The environment in which a Mule app is deployed.

| Cluster | The name of the cluster containing the replicas and worker nodes.

| CPU Limit | The maximum amount of CPU the application can use. This is shared CPU on the worker node.

| CPU Reserve (Millicores) | The amount of CPU guaranteed to the application and reserved for its use.

| Mule Flows | The sum of flows in the Mule app. This number is calculated by multiplying flows by the number of workers (CloudHub) or replicas (CloudHub 2.0). For more information about how this metric is billed, see xref:usage-metrics.adoc#mule-flows[Mule flows].

| Mule Messages | The sum of inbound and outbound Mule messages in the Mule app. For more information about how this metric is billed, see xref:usage-metrics.adoc#mule-messages[Mule messages].  

| Data Throughput (GB) | The sum of inbound and outbound data in gigabytes (GB) transmitted by the Mule app. For more information about how this metric is billed, see xref:usage-metrics.adoc#data-throughput[data throughput].  
|===

=== Mule Runtime Usage Cards

MuleSoft usage reports cards include:

* <<max-mule-flows>>
* <<mule-messages>>
* <<max-cpu-prod>>
* <<max-cpu-preprod>>
* <<max-cluster-prod>>
* <<max-cluster-preprod>>

[[max-mule-flows]]
=== Maximum Mule Flows

A Mule flow is a sequence of logical operations configured within the XML `<flow/>` element of a Mule application. The runtime report tracks the Mule flows within a deployed and running Mule application that contains a Mule event source or APIkit route requests. Mule apps in production environments typically use multiple Mule flows and subflows to divide the app into functional modules or for error-handling purposes. For example, one Mule flow might receive a record and transform data into a given format that another flow processes.  

To calculate usage, MuleSoft tracks the number of Mule flows for all business groups, environments, and applications. The maximum number of Mule flows within a day or month is identified based on the peak hour across the day or month. For the detailed breakdown, MuleSoft shows the peak hour usage per business group, environment, and application. 

In a usage report, flow counts are calculated by multiplying the number of flows in an app by the number of workers (CloudHub) or replicas (Runtime Fabric and CloudHub 2.0).

==== Mule Flow Scenarios that Count Towards Your Anypoint Platform Package Allotment

The following Mule flows count towards your allotment:
 
* Flows that contain a xref:mule-runtime::about-mule-event.adoc[Mule event source] 
* xref:apikit::index.adoc[Flows generated by APIkit] that process API requests 

Mule flows are charged only when the application containing the Mule flow is deployed and running. 

==== Mule Flow with an Event Source

The following Mule flow contains an event source as the first element. In this case, the `listener` counts towards your allotment.

[source,xml]
----
<flow name="test-flow" >
        <http:listener config-ref="cocheras-puerto-madero-api-httpListenerConfig" path="/daily-report"/>
         <logger level="INFO" message="#[output json --- attributes.queryParams]" />	
</flow>
----

==== Examples of Event Sources

[cols="2*",options="header"]
|===
| Connector | Source

| aggregators | aggregator-listener
| amqp | listener
| anypoint-mq | subscriber
.2+| apikit-odata | request-entity-collection-listener | request-entity-listener
.3+| as2-mule4 | as2-listener | as2-mdn-listener | non-repudiation-listener
| azure-service-bus-messaging | message-listener
| core | scheduler
| db | listener
.2+| email | listener-imap | listener-pop3
| file | listener
| ftp | listener
| ftps | listener
.3+| google-sheets | new-row-listener | new-spreadsheet-listener | updated-row-listener
| http | listener
| ibm-mq| listener
| jms | listener
.2+| kafka | batch-message-listener | message-listener
| mllp | mllp-listener
.4+| netsuite | deleted-object-listener | modified-object-listener | modified-record-listener | new-record-listener
| pubsub | message-listener
.7+| salesforce | deleted-object-listener | modified-object-listener | new-object-listener | replay-channel-listener | replay-topic-listener | subscribe-channel-listener | subscribe-topic-listener
.2+| sap | document-listener | function-listener
| servicebus | listener
| sftp | listener
| sockets | listener
.2+| solace | queue-listener | topic-listener
.2+| sqs | receive-messages | receivemessages
.3+| stripe | citizen-on-new-charge-listener | on-new-charge-listener | on-new-event-listener
| vm | listener
.2+| websocket | inbound-listener | outbound-listener
|===

==== Mule Flow Generated by APIkit and Used for Routing APIkit Requests

APIkit is a tool that simplifies the implementation of APIs by automatically generating a minimal set of Mule flows based on the API specification. Each APIkit router endpoint counts as a distinct Mule flow. These Mule flows do not have an event source and are used for the handling of HTTP requests for a particular API method and path.

Here is an example of an APIkit request:

This flow routes APIkit requests and handles the GET request in the `/reservation` path:

[source,xml]
----
<flow name="get:\reservation:cocheras-puerto-madero-api-config">
        <logger level="INFO" message="#[output json --- attributes.queryParams]" />
</flow>
----

[[non-billable-flows]]
==== Mule Flows That Don't Count Against Your Anypoint Platform Package Allotment 

Mule flows that don't have an event source and aren't used for routing APIkit requests aren’t charged against your Anypoint Platform package allotment. These Mule flows are primarily used to modularize code.

Example:

[source,xml]
----
2.a - Flow with only a logger component
<flow name="just-logging">
        <logger level="INFO" message="#[output json --- attributes.queryParams]" />
</flow>
----

[[mule-messages]]
=== Total Mule Messages

A Mule message is the data (the payload and its attributes) that passes through one or more Mule flows in an application. A Mule message is part of a Mule event, which is generated when the event source within a Mule flow is triggered. For example, a Mule event that consists of a Mule message is created when an HTTP listener receives a request or each time the scheduler component triggers an execution of the Mule flow. 
Mule message processors in a Mule flow (such as core components, file read operations, or the HTTP request operations) can then retrieve, set, and process Mule message data that resides in the Mule event according to their configurations. 
A Mule message is immutable, so every change to a Mule message results in the creation of a new instance. Each processor in a flow that receives a Mule message returns a new Mule message that consists of a message payload (the body of the message) and message attributes (metadata associated with the message).

[[billable-mule-messages]]
==== Mule Message Scenarios that Count Towards Your Anypoint Platform Package Allotment

When an event source within a flow of a Mule application is triggered, the event source such as HTTP Listener or Scheduler, generates a Mule event that encapsulates a Mule message. The Mule message generated by the event source counts towards your Anypoint Platform package allotment. New instances of that message, which can be created during the processing of the original message as it moves through other processors in connected Mule flows, do not count towards your Anypoint Platform package allotment.

[[data-throughput]]
=== Total Data Throughput

Data throughput is all of the network I/O bytes produced by the infrastructure that starts and runs the Mule Runtime server that runs a Mule application. This includes the data that the application produces to execute its business logic, as well as internal operational network traffic such as logs, health-checks, and monitoring traffic. For example, data throughput includes inserting a record into a database and the network traffic associated with the infrastructure of the app, such as log forwarding, control plane connection, and monitoring metrics transfer.  

[[max-cpu-prod]]
=== Maximum CPU Limit in Production

Usage reports enable you to see your CPU limits broken out by business group. The CPU limit is further broken out by application, which helps you identify which application is using the most CPU limit, so you can make adjustments to your application configurations. 

The maximum CPU limit in production is the maximum amount of CPU an app can use when deployed and running in the production runtime plane. This is shared CPU on the worker node. Each member of a set of workers for the same app can have a different value for the CPU limit. Data is captured every 30 minutes as the autoscale policy can execute every 30 minutes, which can impact the worker count and CPU limit of an app.
 
==== Example

This is an example with two apps:

App1 has a CPU Limit of one each and a worker count range of 1-3.

App2 has a CPU Limit of one each and a worker count range of 2-5.

Data captured at 00:30 minutes:

* App 1: sum(1,1,1) = 3
* App 2: sum(1,1,1,1,1) 
* Max metric = 5 CPU Limit aggregated

Redeployment of App1 with a CPU Limit of 2 and worker range of 1 - 6 at 00:45 minutes:

* App 1: sum(1,1,1,2,2,2) = 9
* App 2: sum(1,1,1,1,1) = 5
* Max metric = 14 CPU Limit aggregated

Time 00:60 min: 

* App 1: sum(2,2,2,2,2,2) = 12
* App 2: sum(1,1,1,1,1) = 5
* Max metric = 17 CPU Limit aggregated
* For the root organization in a given hour:
+
Max concurrent limit CPU = 17
* For the root organization in given day:
+
Max concurrent limit CPU = 17
* For the root organization in given month:
+
Max concurrent limit CPU = 17

App 2 auto scales down to three workers after 01:60 min:

* App 1: sum(2,2,2,2,2,2) = 12
* App 2: sum(1,1,1) =3
* Max metric = 15 CPU Limit aggregate
* For the root organization in a given hour:
+
Max concurrent limit CPU = 15
* For the root organization in given day:
+
Max concurrent limit CPU = 17
* For the root organization in given month:
+
Max concurrent limit CPU = 17


[[max-cpu-preprod]]
=== Maximum CPU Limit in Preproduction

The maximum CPU limit in preproduction is the maximum amount of CPU an app can use when deployed and running in preproduction. 

[[max-cluster-prod]]
=== Maximum Cluster Capacity in Production

Your maximum cluster capacity depends on your cluster configuration. 

See xref:runtime-fabric::rtf-cluster-config.adoc[]

[[max-cluster-preprod]]
=== Maximum Cluster Capacity in Preproduction

Your maximum cluster capacity depends on your cluster configuration. 

See xref:runtime-fabric::rtf-cluster-config.adoc[]

== See Also

* xref:usage-reports.adoc[]
